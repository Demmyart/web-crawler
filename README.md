# web-crawler

One of the most common action for any user - searching for some data on the Internet.
There is a countless number of possibilities to do that. The most obvious way is the usage of
search engines. However, their flexibility is limited and they cannot be customized for some
specific cases. To solve this problem, we present a universal tool for web-crawling.
Keywords: dark web, search engine, crawler, web.


The main components are described below:
* Angular - frontend part of the application based on the platform that makes it easy to build
applications with the web.
* PHP - the programming language used to proceed backend logic.
* NGINX - web server to host develped backend and frontend parts of the application.
* PostgreSQL - database for information collection.
* RabbitMQ - message-broker software.
* Symfony - PHP framework, the latest version of which (Symfony 4) is designed for mi-
croservices as it became a very light-weight framework and that is why it fits our project the
best.
* Docker - the Docker containers are used for easily deployment and managing of appliations
parts.
* Tails - live operating system preserving privacy and anonymity.
